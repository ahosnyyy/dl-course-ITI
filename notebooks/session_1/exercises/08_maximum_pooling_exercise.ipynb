{
  "metadata": {
    "jupytext": {
      "formats": "md,ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "exercise-maximum-pooling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction #\n",
        "\n",
        "In these exercises, you'll conclude the feature extraction begun in Exercise 2, explore how invariance is created by maximum pooling, and then look at a different kind of pooling: *average* pooling.\n",
        "\n",
        "Run the cell below to set everything up."
      ],
      "metadata": {
        "id": "PrjPG94qFFzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import learntools.computer_vision.visiontools as visiontools\n",
        "\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "57GXlQ32FFzE",
        "outputId": "03fafb1c-fe02-498a-829c-0351f87abdf9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ba0142985d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgridspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlearntools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputer_vision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisiontools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvisiontools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautolayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'learntools'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell to get back to where you left off in the previous lesson. We'll use a predefined kernel this time."
      ],
      "metadata": {
        "id": "xOsnWnvsFFzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image\n",
        "image_path = './car_illus.jpg'\n",
        "image = tf.io.read_file(image_path)\n",
        "image = tf.io.decode_jpeg(image, channels=1)\n",
        "image = tf.image.resize(image, size=[400, 400])\n",
        "\n",
        "# Embossing kernel\n",
        "kernel = tf.constant([\n",
        "    [-2, -1, 0],\n",
        "    [-1, 1, 1],\n",
        "    [0, 1, 2],\n",
        "])\n",
        "\n",
        "# Reformat for batch compatibility.\n",
        "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "image = tf.expand_dims(image, axis=0)\n",
        "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
        "kernel = tf.cast(kernel, dtype=tf.float32)\n",
        "\n",
        "image_filter = tf.nn.conv2d(\n",
        "    input=image,\n",
        "    filters=kernel,\n",
        "    strides=1,\n",
        "    padding='VALID',\n",
        ")\n",
        "\n",
        "image_detect = tf.nn.relu(image_filter)\n",
        "\n",
        "# Show what we have so far\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(131)\n",
        "plt.imshow(tf.squeeze(image), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Input')\n",
        "plt.subplot(132)\n",
        "plt.imshow(tf.squeeze(image_filter))\n",
        "plt.axis('off')\n",
        "plt.title('Filter')\n",
        "plt.subplot(133)\n",
        "plt.imshow(tf.squeeze(image_detect))\n",
        "plt.axis('off')\n",
        "plt.title('Detect')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "7dJ8f0OrFFzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Apply Pooling to Condense #\n",
        "\n",
        "For for the last step in the sequence, apply maximum pooling using a $2 \\times 2$ pooling window. You can copy this code to get started:\n",
        "\n",
        "```\n",
        "image_condense = tf.nn.pool(\n",
        "    input=image_detect,\n",
        "    window_shape=____,\n",
        "    pooling_type=____,\n",
        "    strides=(2, 2),\n",
        "    padding='SAME',\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "g4dcWBFtFFzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "image_condense = ____"
      ],
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "V_VUz6SRFFzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the next cell to see what maximum pooling did to the feature!"
      ],
      "metadata": {
        "id": "FYkKFBTcFFzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(tf.squeeze(image_detect))\n",
        "plt.axis('off')\n",
        "plt.title(\"Detect (ReLU)\")\n",
        "plt.subplot(122)\n",
        "plt.imshow(tf.squeeze(image_condense))\n",
        "plt.axis('off')\n",
        "plt.title(\"Condense (MaxPool)\")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "EFY8I07_FFzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Average Pooling #\n",
        "\n",
        "We mentioned in the previous exercise that average pooling has largely been superceeded by maximum pooling within the convolutional base. There is, however, a kind of average pooling that is still widely used in the *head* of a convnet. This is **global average pooling**. A `GlobalAvgPool2D` layer is often used as an alternative to some or all of the hidden `Dense` layers in the head of the network, like so:\n",
        "\n",
        "```\n",
        "model = keras.Sequential([\n",
        "    pretrained_base,\n",
        "    layers.GlobalAvgPool2D(),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "```\n",
        "\n",
        "What is this layer doing? Notice that we no longer have the `Flatten` layer that usually comes after the base to transform the 2D feature data to 1D data needed by the classifier. Now the `GlobalAvgPool2D` layer is serving this function. But, instead of \"unstacking\" the feature (like `Flatten`), it simply replaces the entire feature map with its average value. Though very destructive, it often works quite well and has the advantage of reducing the number of parameters in the model.\n",
        "\n",
        "Let's look at what `GlobalAvgPool2D` does on some randomly generated feature maps. This will help us to understand how it can \"flatten\" the stack of feature maps produced by the base."
      ],
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "721ul5s4FFzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## That's it!"
      ],
      "metadata": {
        "id": "jdHaxizPFnvq"
      }
    }
  ]
}