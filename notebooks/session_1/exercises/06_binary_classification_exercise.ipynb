{
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "formats": "ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "06_binary_classification_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction #\n",
        "\n",
        "In this exercise, you'll build a model to predict hotel cancellations with a binary classifier."
      ],
      "metadata": {
        "id": "uZwBu0XDs5dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup plotting\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "# Set Matplotlib defaults\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('animation', html='html5')"
      ],
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "xjnLXJqms5dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, load the *Hotel Cancellations* dataset."
      ],
      "metadata": {
        "id": "r4Yh4j0ks5dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "hotel = pd.read_csv('./hotel.csv')\n",
        "\n",
        "X = hotel.copy()\n",
        "y = X.pop('is_canceled')\n",
        "\n",
        "X['arrival_date_month'] = \\\n",
        "    X['arrival_date_month'].map(\n",
        "        {'January':1, 'February': 2, 'March':3,\n",
        "         'April':4, 'May':5, 'June':6, 'July':7,\n",
        "         'August':8, 'September':9, 'October':10,\n",
        "         'November':11, 'December':12}\n",
        "    )\n",
        "\n",
        "features_num = [\n",
        "    \"lead_time\", \"arrival_date_week_number\",\n",
        "    \"arrival_date_day_of_month\", \"stays_in_weekend_nights\",\n",
        "    \"stays_in_week_nights\", \"adults\", \"children\", \"babies\",\n",
        "    \"is_repeated_guest\", \"previous_cancellations\",\n",
        "    \"previous_bookings_not_canceled\", \"required_car_parking_spaces\",\n",
        "    \"total_of_special_requests\", \"adr\",\n",
        "]\n",
        "features_cat = [\n",
        "    \"hotel\", \"arrival_date_month\", \"meal\",\n",
        "    \"market_segment\", \"distribution_channel\",\n",
        "    \"reserved_room_type\", \"deposit_type\", \"customer_type\",\n",
        "]\n",
        "\n",
        "transformer_num = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\"), # there are a few missing values\n",
        "    StandardScaler(),\n",
        ")\n",
        "transformer_cat = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n",
        "    OneHotEncoder(handle_unknown='ignore'),\n",
        ")\n",
        "\n",
        "preprocessor = make_column_transformer(\n",
        "    (transformer_num, features_num),\n",
        "    (transformer_cat, features_cat),\n",
        ")\n",
        "\n",
        "# stratify - make sure classes are evenlly represented across splits\n",
        "X_train, X_valid, y_train, y_valid = \\\n",
        "    train_test_split(X, y, stratify=y, train_size=0.75)\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_valid = preprocessor.transform(X_valid)\n",
        "\n",
        "input_shape = [X_train.shape[1]]"
      ],
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "DaZQeh-us5dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Define Model #\n",
        "\n",
        "The model we'll use this time will have both batch normalization and dropout layers. To ease reading we've broken the diagram into blocks, but you can define it layer by layer as usual.\n",
        "\n",
        "Define a model with an architecture given by this diagram:\n",
        "\n",
        "<figure style=\"padding: 1em;\">\n",
        "<img src=\"https://i.imgur.com/V04o59Z.png\" width=\"400\" alt=\"Diagram of network architecture: BatchNorm, Dense, BatchNorm, Dropout, Dense, BatchNorm, Dropout, Dense.\">\n",
        "<figcaption style=\"textalign: center; font-style: italic\"><center>Diagram of a binary classifier.</center></figcaption>\n",
        "</figure>\n"
      ],
      "metadata": {
        "id": "lJdejREns5dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# YOUR CODE HERE: define the model given in the diagram\n",
        "model = ____"
      ],
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "L7eELMiAs5dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Add Optimizer, Loss, and Metric #\n",
        "\n",
        "Now compile the model with the Adam optimizer and binary versions of the cross-entropy loss and accuracy metric."
      ],
      "metadata": {
        "id": "tJV4kiWHs5dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "____"
      ],
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "NlFg8tW5s5d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, run this cell to train the model and view the learning curves. It may run for around 60 to 70 epochs, which could take a minute or two."
      ],
      "metadata": {
        "id": "Vrwpddy4s5d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    batch_size=512,\n",
        "    epochs=200,\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
        "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")"
      ],
      "metadata": {
        "id": "wnfVT7Vss5d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## That's it!"
      ],
      "metadata": {
        "id": "MnQeDbe0s5d1"
      }
    }
  ]
}